{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "398e8ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Referensi:\n",
    "\n",
    "# docx2txt\n",
    "# https://github.com/ankushshah89/python-docx2txt\n",
    "\n",
    "# Job Scrape from Web\n",
    "# https://www.youtube.com/watch?v=eN_3d4JrL_w\n",
    "# github dari YouTube di atas: https://github.com/israel-dryer/Indeed-Job-Scraper\n",
    "# https://www.geeksforgeeks.org/how-to-scrape-multiple-pages-of-a-website-using-python/\n",
    "\n",
    "# Pencocokan Resume dan Job Scrape\n",
    "# https://randerson112358.medium.com/resume-scanner-2c30f5baf92c\n",
    "\n",
    "# Our Location\n",
    "# https://geocoder.readthedocs.io/providers/IPInfo.html#geocode-your-own-ip\n",
    "# https://stackoverflow.com/questions/30218394/timeout-error-in-python-geopy-geocoder\n",
    "\n",
    "# Google Translate Library\n",
    "# https://cloud.google.com/translate/docs/basic/translating-text#translating_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02c8d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pencocokkan Resume yang di upload dengan laman pekerjaan Indeed (Indonesia)\n",
    "\n",
    "import docx2txt\n",
    "import re\n",
    "import requests\n",
    "import geocoder\n",
    "import time\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from random import randint\n",
    "from docx import Document\n",
    "import six\n",
    "from google.cloud import translate_v2 as translate\n",
    "\n",
    "# Proses document '.docx' agar bisa dibaca dan menggantikan tab dengan spasi\n",
    "def find_text_from_docx(docx):\n",
    "    text = docx2txt.process(docx)\n",
    "    if text:\n",
    "        return text.replace('\\t', ' ')\n",
    "    return None\n",
    "\n",
    "\n",
    "def per_page_scrape(job, place, docx):\n",
    "    document = Document()\n",
    "    \n",
    "    # pattern link per page\n",
    "    jk_pattern = re.compile(r\"jk:\\'([a-zA-Z0-9]+)'\")\n",
    "    \n",
    "    # ganti spasi di input jadi '+' biar nyambung dengan link\n",
    "    job = job.replace(' ', '+')\n",
    "    place  = place.replace(' ', '+')\n",
    "    \n",
    "    # parameter link\n",
    "    params = { \"q\": job, \"l\": place, \"start\": 0 }\n",
    "    url = \"https://id.indeed.com/lowongan-kerja\"\n",
    "    job_keys = set()\n",
    "    \n",
    "    # contoh link: https://id.indeed.com/lowongan-kerja?q=full+stack&l=jakarta\n",
    "    \n",
    "    # Cek per page untuk pattern link\n",
    "    for page in range(0, 4):\n",
    "        response = requests.get(url, params=params)\n",
    "        if not response.status_code == 200:\n",
    "            break\n",
    "        else:\n",
    "            keys = jk_pattern.findall(response.text)\n",
    "            if len(keys) > 0:\n",
    "                for key in keys:\n",
    "                    job_keys.add(key)\n",
    "            \n",
    "            template = \"https://id.indeed.com/viewjob?jk={}\"\n",
    "            # pattern link di pop ke template\n",
    "            jk = job_keys.pop()\n",
    "            # template di format dengan dimasukkan pattern ke {}\n",
    "            job_url = template.format(jk)\n",
    "            # akses link\n",
    "            response = requests.get(job_url)\n",
    "            \n",
    "            # Parse Webpage\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            # Buat title di Webpage sebagai penanda di hasil '.docx'\n",
    "            document.add_paragraph(soup.find(\"h1\", attrs={\"class\": \"icl-u-xs-mb--xs icl-u-xs-mt--none jobsearch-JobInfoHeader-title\"}).text)\n",
    "            # Cari deskripsi pekerjaan dan dibuat jadi text\n",
    "            job_description = soup.find(\"div\", id=\"jobDescriptionText\").text\n",
    "            \n",
    "            # Translate dari English ke Indonesia\n",
    "            translate_client = translate.Client()\n",
    "            if isinstance(job_description, six.binary_type):\n",
    "                job_description = job_description.decode(\"utf-8-sig\")\n",
    "            result = translate_client.translate(job_description, target_language=\"id\", model=\"nmt\")\n",
    "            \n",
    "            # Hasil translate dibersihkan dengan menghilangkan '&#39;' dan diganti dengan enter\n",
    "            translated_texts = result[\"translatedText\"]\n",
    "            clean_job_description = translated_texts.replace('&#39;', '\\n')\n",
    "            \n",
    "            # Masukkan hasil translate bersih ke '.docx'\n",
    "            document.add_paragraph(clean_job_description)\n",
    "            document.add_paragraph(job_url)\n",
    "            \n",
    "            # Memasukkan resume dan hasil translate bersih ke dalam 2 masing-masing array\n",
    "            list = [docx, clean_job_description]\n",
    "            \n",
    "            # Penjelasan: https://blog.kmkonline.co.id/were-doing-machine-learning-9d4075d46cc3\n",
    "            cv = CountVectorizer()\n",
    "            count_matrix = cv.fit_transform(list)\n",
    "            \n",
    "            # Similarity score\n",
    "            matchPercentage = cosine_similarity(count_matrix)[0][1] * 100\n",
    "            matchPercentage = round(matchPercentage, 2)\n",
    "            \n",
    "            document.add_paragraph(\"Resume mempunyai kesamaan sebesar: \"+ str(matchPercentage)+ \"% dari deskripsi pekerjaan.\")\n",
    "            document.add_page_break()\n",
    "        \n",
    "        # Untuk pergi ke Webpage selanjutnya\n",
    "        params['start'] += 10\n",
    "        sleep(randint(1,4))\n",
    "        \n",
    "    # Save document \n",
    "    document.save('Hasil.docx')\n",
    "\n",
    "# Untuk mengambil lokasi kota pengguna\n",
    "g = geocoder.ipinfo('me')\n",
    "time.sleep(8)\n",
    "curr_city = g.city\n",
    "time.sleep(8)\n",
    "\n",
    "# Lokasi resume pengguna\n",
    "file_location = 'Adhi Gopalam - SM.en.id.docx'\n",
    "\n",
    "# Posisi pekerjaan yang diinginkan\n",
    "wanted_job_position = \"full stack\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    per_page_scrape(wanted_job_position, curr_city, find_text_from_docx(file_location))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
